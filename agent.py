import os

from config import Config
from storage import StorageManager
from memory import MemoryManager
from knowledge_base import KnowledgeBase
from llm_service import LLMService

class Agent:
    def __init__(self):
        self.storage = StorageManager()
        self.memory = MemoryManager()
        self.kb = KnowledgeBase()
        self.llm = LLMService()

    def handle_upload(self, file_path):
        if not os.path.exists(file_path):
            return "âŒ æ–‡ä»¶ä¸å­˜åœ¨"
        try:
            url = self.storage.upload_file(file_path)
            self.kb.ingest_document(file_path, url)
            return "âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼"
        except Exception as e:
            return f"âŒ å¤„ç†å¤±è´¥: {str(e)}"

    def handle_chat(self, session_id, query):
        # 1. æŸ¥å†å²
        history = self.memory.get_history(session_id)

        # 2. æŸ¥çŸ¥è¯†åº“ (RAG)
        contexts = self.kb.search(query)
        context_str = "\n".join([f"- {c}" for c in contexts])

        # 3. ç»„è£… Prompt
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¼ä¸šçº§æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
        å¦‚æœä¸Šä¸‹æ–‡æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´ä¸çŸ¥é“ã€‚

        ã€å‚è€ƒçŸ¥è¯†åº“ã€‘ï¼š
        {context_str}
        """

        # 4. ç”Ÿæˆå›ç­”
        print(f"\nğŸ” [Debug] Retrieved Contexts: {len(contexts)}")
        answer = self.llm.chat(system_prompt, history, query)

        # 5. å­˜å…¥è®°å¿†
        self.memory.add_history(session_id, "user", query)
        self.memory.add_history(session_id, "assistant", answer)

        return answer